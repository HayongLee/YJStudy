# CPU 스케줄링


* [CPU 스케줄링](#cpu-스케줄링)
* [CPU 스케줄러](#cpu-스케줄러)
* [디스패처](#디스패처)
* [스케줄링의 성능 평가](#스케줄링의-성능-평가)
* [스케줄링 알고리즘](#스케줄링-알고리즘)
    * [FCFS](#fcfs)
    * [SJF](#sjf)
    * [우선순위 스케줄링](#우선순위-스케줄링)
    * [라운드 로빈 스케줄링](#라운드-로빈-스케줄링)
    * [멀티 레벨 큐](#멀티-레벨-큐)
    * [멀티 레벨 피드백 큐](#멀티-레벨-피드백-큐)
    * [다중 처리기 스케줄링](#다중-처리기-스케줄링)
    * [실시간 스케줄링](#실시간-스케줄링)
* [스케줄링 알고리즘의 평가](#스케줄링-알고리즘의-평가)


&nbsp;      
## CPU 스케줄링
CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙 처리 장치이다. CPU는 일반적으로 시스템 내에 하나밖에 없으므로 여러 프로그램이 동시에 수행되는 시분할(time sharing) 환경에서 CPU는 매우 효율적으로 관리되어야 하는 자원이다.


기계어 명령은 크게 CPU 내에서 수행되는 명령, 메모리 접근을 필요로 하는 명령, 입출력을 동반하는 명령으로 나뉜다.
* CPU 내에서 수행되는 명령의 예로 Add 명령은 CPU 내의 레지스터에 있는 두 값을 더해 레지스터에 저장하는 명령이다. CPU 내에서만 수행되므로 명령의 수행 속도가 매우 빠르다.
* 메모리 접근을 수행하는 명령으로는 Load와 Store 명령이 있다. Load 명령은 메모리에 있는 데이터를  CPU로 읽어 들이는 명령이며, Store 명령은 CPU에서 계산된 결과값을 메모리에 저장하는 명령이다. CPU 내에서 수행되는 명령보다는 시간이 오래 소요되지만 비교적 짧은 시간에 수행할 수 있는 명령에 해당된다.
    * CPU 내에서 일어나는 명령이나 메모리에 접근하는 명령은 사용자 프로그램이 직접 실행 가능한 일반 명령에 해당한다.
* 입출력을 수반하는 명령은 대단히 오랜 시간이 소요된다. 또한, 컴퓨터 시스템에서는 모든 입출력 명령을 특권 명령으로 규정해 사용자 프로그램이 직접 수행할 수 없도록 하고 운영 체제를 통해 서비스를 대행하도록 하고 있다.


사용자 프로그램이 수행되는 과정을 보면 CPU 작업과 I/O 작업의 반복으로 구성된다. 일종의 사이클처럼 CPU와 I/O 장치라는 상이한 자원을 번갈아 사용하면서 프로그램이 수행되는 것으로 볼 수 있다. 프로그램의 수행을 서로 다른 두 단계에 조합으로 나누면 
* 그 첫째는 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 일련의 단계이고(CPU 버스트),
* 둘째는 I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 비교적 느린 단계이다(I/O 버스트).


즉, 프로그램이 I/O를 한 번 수행한 후 다음번 I/O를 수행하기까지 직접 CPU를 가지고 명령을 수행하는 일련의 작업을 CPU 버스트라고 부른다. I/O 버스트는 I/O 작업이 요청된 후 완료되어 다시 CPU 버스트로 돌아가기까지 일어나는 일련의 작업을 말한다.


프로세스를 크게 I/O 바운드 프로세스(I/O bound process)와 CPU 바운드 프로세스(CPU bound process)로 나누어 볼 수 있다.
* I/O 바운드 프로세스는 I/O 요청이 빈번해 CPU 버스트가 짧게 나타나는 프로세스를 말하고, 
* CPU 바운드 프로세스는 I/O 작업을 거의 수행하지 않아 CPU 버스트가 길게 나타나는 프로세스를 말한다.
* I/O 바운드 프로세스는 주로 사용자로부터 인터액션을 계속 받아 가며 프로그램을 수행시키는 대화형 프로그램(interactive program)이 이에 해당하고, CPU 바운드 프로세스는 프로세스 수행의 상당 시간을 입출력 작업 없이 CPU 작업에 소모하는 계산 위주의 프로그램이 해당된다.
* 프로그램이 수행되는 구조를 보면 I/O 바운드 프로세스는 짧은 CPU 버스트를 많이 가지고 있는 반면, CPU 바운드 프로세스는 소수의 긴 CPU 버스트로 구성된다.


CPU 스케줄링이란 이와 같이 CPU를 사용하는 패턴이 상이한 여러 프로그램이 동일한 시스템 내부에서 함께 실행되기 때문에 필요한 것이다.


프로세스들의 CPU 버스트 분포는 다수의 짧은 CPU 버스트와 소수의 긴 CPU 버스트로 구성된다. CPU 버스트가 짧은 프로세스는 대부분 대화형 작업(interactive job)으로 사용자와 인터액션을 해가며 프로그램을 수행시킨다. 즉, 사용자에게 입력을 받아 CPU 연산을 수행하고 그 결과를 다시 출력하는 작업을 수행한다. 대화형 작업은 사용자에 대한 빠른 응답이 중요하기 때문에 CPU 스케줄링을 할 때 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 사용할 수 있도록 하는 스케줄링이 필요하다. 이는 CPU 스케줄링 시 I/O 바운드 프로세스에게 우선순위를 높여 주는 것이 바람직하다는 의미가 된다. 이러한 스케줄링은 대화형 프로세스의 빠른 응답성 제공 외에 I/O 장치의 효율성을 높이는 효과도 얻을 수 있다. I/O 바운드 프로세스에게 먼저 CPU를 할당할 경우 CPU를 잠깐만 사용한 후 곧바로 I/O 작업을 수행할 수 있으므로 I/O 장치의 이용률이 높아지기 때문이다.


&nbsp;      
## CPU 스케줄러
CPU 스케줄러는 준비 상태에 있는 프로세스들 중에 어떠한 프로세스에게 CPU를 할당할지를 결정하는 운영 체제의 코드이다. 어떠한 프로세스가 CPU를 할당받고 기계어 명령을 수행하다가 타이머 인터럽트가 발생하면 CPU 스케줄러가 호출된다. 그러면 CPU 스케줄러는 준비 큐에서 CPU를 기다리는 프로세스 중 하나를 선택해 CPU를 할당하게 된다.


다음은 CPU 스케줄링이 발생하는 상황을 분류한 것이다.
1. 실행 상태에 있던 프로세스가 I/O 요청 등에 의해 봉쇄(blocked) 상태로 바뀌는 경우(비선점형 스케줄링 방식)
2. 실행 상태에 있던 프로세스가 타이머 인터럽트 발생에 의해 준비 상태로 바뀌는 경우(선점형 스케줄링 방식)
3. I/O 요청으로 봉쇄 상태에 있던 프로세스의 I/O 작업이 완료되어 인터럽트가 발생하고 그 결과 이 프로세스의 상태가 준비 상태로 바뀌는 경우(선점형 스케줄링 방식)
4. CPU에서 실행 상태에 있는 프로세스가 종료되는 경우(비선점형 스케줄링 방식)


CPU 스케줄링 방식에는 비선점형 방식과 선점형 방식이 있다.
* 비선점형(nonpreemptive) 방식이란 CPU를 획득한 프로세스가 스스로 CPU를 반납하기 전까지는 CPU를 빼앗기지 않는 방법을 말한다.
* 선점형(preemptive) 방식은 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링 방법을 말한다. 


CPU를 빼앗는 대표적인 방법으로는 할당 시간(time quantum)을 부여한 후 타이머 인터럽트를 발생시키는 방법이 있다.


&nbsp;      
## 디스패처
CPU 스케줄러가 어떤 프로세스에게 CPU를 할당해야 할지를 결정하고 나면 선택된 프로세스에게 실제로 CPU를 이양하는 작업이 필요하다. 이와 같이 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경 설정을 하는 커널 모듈을 디스패처(dispatcher)라고 부른다.


1. 디스패처는 현재 수행 중이던 프로세스의 문맥(context)을 그 프로세스의 PCB에 저장하고, 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한 후 그 프로세스에게 CPU를 넘기는 과정을 수행한다. 
2. 새로운 프로세스의 문맥을 복원시킨 후에는 사용자 모드로 시스템의 상태를 전환해 사용자 프로그램에게 CPU의 제어권을 넘기게 된다. 그러면 사용자 프로그램은 복원된 문맥 중 프로그램 카운터로부터 현재 수행할 주소를 찾을 수 있게 된다.


디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연 시간(dispatch latency)이라고 부른다. 디스패치 지연 시간의 대부분은 문맥 교환 오버헤드에 해당된다.


&nbsp;      
## 스케줄링의 성능 평가
스케줄링 기법의 성능 평가 지표들은 크게 시스템 관점의 지표와 사용자 관점의 지표로 나뉜다.
* 시스템 관점의 지표로는 CPU 활용도와 처리량이 있으며, 
* 사용자 관점의 지표로는 소요 시간, 대기 시간, 응답 시간 등 기다린 시간과 관련된 지표들이 있다.


#### CPU 활용도(CPU utilization) 
전체 시간 중 CPU가 명령을 수행한 시간의 비율. CPU가 일을 하지 않고 휴면(idle) 상태에 머무르는 시간을 최대한 줄이는 것이 스케줄링의 중요한 목표가 된다.


#### 처리량(throughput)
주어진 시간 동안 CPU 버스트를 완료한 프로세스의 개수. CPU의 서비스를 원하는 프로세스 중 몇 개가 원하는 만큼의 CPU를 사용하고 이번 CPU 버스트를 끝내어 준비 큐를 떠났는지를 측정한 것으로 여러 프로세스가 CPU를 기다리고 있는 상황에서 주어진 시간에 더 많은 프로세스들이 CPU 작업을 완료하기 위해서는 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 할당하는 것이 유리하다.


#### 소요 시간(turnaround time)
프로세스가 CPU 요청 시점부터 CPU 버스트가 끝날 때까지 걸린 시간. 준비 큐에서 기다린 시간과 실제로 CPU를 사용한 시간의 합을 뜻한다. 이는 해당 CPU 버스트가 완료될 때까지 소요된 시간으로, 프로그램이 시작해 종료하는 데까지 걸리는 시간이 아님에 주의해야 한다. 프로그램이 시작해서 종료하기까지 CPU 버스트는 여러 차례 있을 수가 있고 우리는 지금 CPU에만 관심이 있기 때문에 하나의 프로세스라 하더라도 소요 시간은 CPU 버스트의 수만큼 각각 별도로 측정되기 때문이다.


#### 대기 시간(waiting time)
프로세스가 CPU 버스트 기간 중 준비 큐에서 기다린 시간의 합. 시분할 시스템에서는 일반적으로 타이머를 사용해서 하나의 프로세스가 CPU를 연속적으로 사용할 수 있는 시간을 제한하고 있다. 따라서, 한 번의 CPU 버스트 중에도 준비 큐에서 기다린 시간이 여러 번 발생할 수 있다. 이때 대기 시간이란 이번 CPU 버스트가 끝나기까지 준비 큐에서 기다린 시간의 합을 뜻한다.


#### 응답 시간(response time)
프로세스가 CPU 요청 시점부터 처음으로 CPU를 얻을 때까지 기다린 시간. 준비 큐에 들어온 직후부터 첫 번째 CPU를 얻기까지 걸린 시간만을 나타낸다. 타이머 인터럽트가 빈번히 발생할수록 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 짧아지므로 처음 CPU를 얻기까지 걸리는 시간은 줄어들게 되어 응답 시간이 향상된다. 응답 시간은 대화형 시스템에 적합한 성능 척도로 이는 사용자 입장에서 가장 중요한 성능 척도라 할 수 있다.


&nbsp;      
## 스케줄링 알고리즘
### FCFS
FCFS(First-Come First-Served) 스케줄링은 프로세스가 준비 큐에 도착한 시간 순서대로 CPU를 할당하는 방식. 


CPU를 먼저 요청한 프로세스에게 CPU를 먼저 할당하고, 그 프로세스가 자발적으로 CPU를 반납할 때까지 CPU를 선점하지 않는다. 경우에 따라 비효율적인 결과를 초래하기도 하는데 CPU 버스트가 긴 프로세스 하나가 CPU 버스트가 짧은 프로세스 여러 개보다 먼저 도착한 경우 CPU를 잠깐만 사용하면 준비 큐를 떠나 I/O 작업을 수행할 수 있는 다수의 프로세스들이 앞의 긴 작업 하나 때문에 계속 기다려야 하므로 평균 대기 시간(average waiting time)이 길어지게 되고 I/O 장치들의 활용도까지도 동반 하락하게 된다.


FCFS 스케줄링 알고리즘에서는 먼저 도착한 프로세스의 성격에 따라 평균 대기 시간이 크게 달라진다.


프로세스 | CPU 버스트 시간
-------- | --------
P1 | 12
P2 | 3
P3 | 3


프로세스의 도착 순서가 P1, P2, P3라 하고 각각의 CPU 버스트 시간이 12, 3, 3이라고 가정할 때, FCFS에 의한 스케줄 순서는:
```
|      P1      | P2 | P3 |
0              12   15   18

대기 시간: P1 = 0, P2 = 12, P3 = 15
평균 대기 시간: (0+12+15)/3 = 9
```


프로세스의 도착 순서가 P2, P3, P1이라고 할 때, 스케줄 순서는:
```
| P2 | P3 |      P1      |
0    3    6              18

대기 시간: P1 = 6, P2 = 0, P3 = 3
평균 대기 시간: (6+0+3)/3 = 3
```


* 두 가지 경우를 비교해 보면, CPU 버스트가 짧은 프로세스가 먼저 도착한 후자의 경우에 평균 대기 시간이 크게 줄어들었음을 알 수 있다.
* 전자의 경우처럼 CPU 버스트가 짧은 프로세스가 CPU 버스트가 긴 프로세스보다 나중에 도착해 오랜 시간을 기다려야 하는 현상을 콘보이 현상(Convoy effect)이라고 하며, 이는 FCFS 스케줄링의 대표적인 단점에 해당된다.


&nbsp;      
### SJF
SJF(Shortest-Job First) 스케줄링 알고리즘은 CPU 버스트가 가장 짧은 프로세스에게 제일 먼저 CPU를 할당하는 방식이다.


이와 같은 할당 방식을 통해 CPU 버스트가 짧은 프로세스가 CPU를 먼저 사용하고 준비 큐를 빠져나가게 되면 프로세스들이 준비 큐에서 기다리는 전체적인 시간이 줄어들게 된다. SJF 스케줄링 알고리즘은 평균 대기 시간(average waiting time)을 가장 짧게 하는 최적의 알고리즘(optimal algorithm)으로 알려져 있다.


SJF 알고리즘은 비선점형 방식과 선점형 방식 두 가지로 구현될 수 있다. 


일반적으로 CPU를 기다리는 프로세스들이 준비 큐에 동시에 도착하지는 않는다. 따라서, 현재 CPU를 할당받고 수행 중인 프로세스가 비록 CPU를 할당받은 시점에서는 CPU 버스트 시간이 가장 짧은 프로세스였다 해도 CPU 버스트 시간이 더 짧은 프로세스가 도착할 수 있다. 이때, 비선점형 방식과 선점형 방식은 서로 다른 조치를 취하게 된다.
* 비선점형 방식에서는 현재 CPU를 점유하고 있는 프로세스가 CPU 버스트를 모두 수행하고 스스로 CPU를 내어놓을 때까지 스케줄링을 하지 않는다. 
* 반면 선점형 방식에서는 CPU 버스트 시간이 더 짧은 프로세스가 도착하면 현재 수행 중인 프로세스에게서 CPU를 선점해 CPU 버스트 시간이 더 짧은 프로세스에게 할당하게 된다. SJF의 선점형 구현 방식을 SRTF(Shortest Remaining Time First)라고 부른다.


프로세스들이 준비 큐에 도착하는 시간이 불규칙한 환경에서는 선점형 방식이 프로세스들의 평균 대기 시간을 최소화하는 최적의 알고리즘이 된다. 일반적으로 시분할 환경에서는 중간중간에 새로운 프로세스가 도착하는 경우가 발생하므로 선점형 방식이 평균 대기 시간을 가장 많이 줄일 수 있는 방식이 된다.


프로세스 | 도착 시간 | CPU 버스트 시간
-------- | -------- | --------
P1 | 0 | 7
P2 | 2 | 3
P3 | 4 | 1
P4 | 5 | 4


네 개의 프로세스 P1, P2, P3, P4가 각각 위와 같은 도착 시간과 CPU 버스트 시간을 가진다고 할 때 SJF 알고리즘의 스케줄링 차트 및 평균 대기 시간은 다음과 같다:
```
SJF 비선점형 스케줄링
|    P1    |P3| P2 | P4 |
0          7  8   12   16

평균 대기 시간: (0+6+3+7)/4 = 4
```


```
SJF 선점형 스케줄링
| P1 | P2 |P3| P2 |  P4  |   P1   |
0    2    4  5    7      11       16

선점형 방식에서는 프로세스가 새롭게 도착하거나 작업이 끝날 때마다 CPU 버스트 시간을 비교하게 된다.
평균 대기 시간: (9+1+0+2)/4 = 3  
```


SJF 스케줄링 기법의 구현에서 어려운 부분은 CPU 버스트 시간을 미리 알 수 없다는 점이다. 그래서 예측을 통해 CPU 버스트 시간을 구한 후 예측치가 가장 짧은 프로세스에게 CPU를 할당하게 된다. CPU 버스트 시간의 예측은 과거의 CPU 버스트 시간을 통해 이루어지는데, 다음과 같은 방법을 사용한다:
* (n+1) 번째 CPU 버스트의 예측 시간 Tn+1은  Tn+1 = α tn + (1-α) Tn
    * tn과 Tn은 각각 n 번째 실제 CPU 버스트 시간과 n 번째 CPU 버스트의 예측 시간을 뜻하며, α는 0과 1 사이의 상수로 두 요소를 어느 정도씩 반영할지를 조절하는 매개 변수(parameter)이다. 
    * α = 0인 경우 Tn+1 = Tn이 되어 고정된 값이 예측값으로 계속 사용된다. α = 1인 경우 Tn+1 = tn이 되어 바로 전에 사용한 CPU 버스트 시간을 예측 값으로 사용하게 된다.
    * α값을 0과 1 사이의 값으로 세팅하면 n 번째 실제 CPU 버스트 시간과 n 번째 버스트 시간의 예측값을 적당히 가중 평균해 n+1번째 CPU 버스트 시간을 예측하게 된다.
    * 과거의 CPU 버스트 시간들을 통해 미래의 CPU 버스트 시간을 예측하는 것으로 최근 CPU 버스트 시간일수록 오래전의 CPU 버스트 시간에 비해 가중치를 높이는 방식이 된다.


SJF 알고리즘이 평균 대기 시간을 최소화하는 알고리즘이기는 하지만 시스템에서 평균을 줄이는 것이 항상 좋은 방식이라고 말할 수 없다. 계속 CPU 버스트가 짧은 프로세스에게만 CPU를 할당할 경우 CPU 버스트가 긴 프로세스는 준비 큐에 줄 서서 무한정 기다려야 하는 문제가 발생할 수 있기 때문이다. 프로세스가 영원히 CPU를 할당받지 못하는 현상을 기아 현상(starvation)이라고 하며, 이는 SJF 알고리즘의 심각한 문제점이 된다.


&nbsp;      
### 우선순위 스케줄링
우선순위 스케줄링(priority scheduling)이란 준비 큐에서 기다리는 프로세스들 중에서 우선순위가 가장 높은 프로세스에게 제일 먼저 CPU를 할당하는 방식을 말한다.


우선순위는 우선순위 값(priority number)을 통해 표시하며 우선순위 값이 작을수록 높은 우선순위를 가지는 것으로 가정한다.


우선순위 스케줄링도 비선점형 방식과 선점형 방식으로 각각 구현할 수 있다. 
* 현재 CPU에서 수행 중인 프로세스보다 우선순위가 높은 프로세스가 도착할 경우 CPU를 선점해 새롭게 도착한 프로세스에게 할당할 경우 선점형 방식이 된다.
* 이와 달리 일단 CPU를 얻었으면 비록 우선순위가 더 높은 프로세스가 도착하더라도 CPU를 자진 반납하기 전까지 선점하지 않는다면 이는 비선점형 방식이 된다.


우선순위 스케줄링 방식에서의 문제점 중 하나는 기아 현상이 발생할 수 있다는 점이다. 우선순위가 높은 프로세스가 계속 도착할 경우 우선순위가 낮은 프로세스는 CPU를 얻지 못한 채 계속 기다려야 하는 상황이 발생할 수 있기 때문이다. 이러한 문제점을 해결하기 위해 노화 기법을 사용할 수 있다.
* 노화 기법이란 기다리는 시간이 길어지면 우선순위를 조금씩 높여 언젠가는 가장 높은 우선순위가 되어 CPU를 할당받을 수 있게 해주는 방법이다.


&nbsp;      
### 라운드 로빈 스케줄링
라운드 로빈 스케줄링(Round Robin Scheduling)은 지금까지 소개한 스케줄링 방식과 달리 시분할 시스템의 성질을 가장 잘 활용한 새로운 의미의 스케줄링 방식이다.


라운드 로빈 스케줄링에서는 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 특정 시간으로 제한되며, 이 시간이 경과하면 이 프로세스로부터 CPU를 회수해 준비 큐에 줄 서 있는 다른 프로세스에게 CPU를 할당하게 된다. 그러면 이 프로세스는 준비 큐의 제일 뒤에 가서 줄을 서서 다음 번 차례가 오기를 기다리게 된다. 이때, 각 프로세스마다 한 번에 CPU를 연속적으로 사용할 수 있는 최대 시간을 할당 시간(time quantum)이라고 부른다.


할당 시간이 너무 길면, FCFS와 같은 결과를, 할당 시간이 너무 짧으면 문맥 교환의 오버헤드가 커지게 된다. 따라서 일반적으로 할당 시간을 수십 밀리 세컨드 정도의 규모로 설정하게 된다. 이는 여러 프로세스가 동시에 수행되는 환경에서 대화형 프로세스가 CPU를 한 번 할당받기까지 지나치게 오래 기다리지 않을 정도의 시간 규모에 해당한다.


라운드 로빈 스케줄링은 여러 종류의 이질적인 프로세스가 같이 실행되는 환경에서 효과적이다. 예를 들어 n 개의 프로세스가 준비 큐에 있고 할당 시간이 q라고 할 때, 모든 프로세스는 (n-1)q 시간 이내에 적어도 한 번은 CPU를 할당받을 수 있게 된다.


이와 같은 방식은 대화형 프로세스의 빠른 응답 시간을 보장할 수 있는 장점이 있다. 그렇다고 이 스케줄링에서 CPU 버스트가 긴 프로세스에게 특별히 불이익이 가는 것도 아니다. 각 프로세스의 대기 시간이 그 프로세스의 CPU 버스트 시간에 비례하기 때문이다. 즉, CPU를 많이 쓰는 프로세스는 대기 시간이 거기에 비례해서 길어지고 반대로 CPU를 적게 쓰는 프로세스는 대기 시간도 짧아지게 된다.


프로세스 | CPU 버스트 시간
-------- | --------
P1 | 24
P2 | 17
P3 | 3


위 표와 같은 CPU 버스트 시간을 가지는 프로세스 P1, P2, P3가 순서대로 도착했을 경우, 할당 시간이 10인 라운드 로빈 스케줄링을 적용하면 그 결과는 아래와 같다:
```
|   P1   |   P2   | P3 |   P1   |  P2  | P1 |
0        10       20  23       33      40  44
```


* 라운드 로빈 스케줄링은 일반적으로 SJF 방식보다 평균 대기 시간은 길지만 응답 시간(response time)은 더 짧다.
* 할당 시간이 만료되어 CPU를 회수하는 방법으로는 타이머 인터럽트를 사용하게 된다. 만약 CPU 버스트 시간이 할당 시간보다 짧으면 CPU를 자신의 버스트 시간만큼 사용한 후 스스로 반납하게 된다.
* 라운드 로빈 스케줄링의 기본적인 목적은 CPU 버스트 시간이 짧은 프로세스가 빨리 CPU를 얻을 수 있도록 하는 동시에, CPU 버스트 시간이 긴 프로세스가 불이익을 당하지 않도록 하는 것이다.


SJF 스케줄링의 경우, 평균 대기 시간 측면에서는 가장 우수한 결과를 보장하지만, 일부의 희생을 통해 전체의 성능을 향상시키는 방법으로 효율성을 높이는 대신 형평성을 지나치게 간과한다. 이에 비해 라운드 로빈 스케줄링은 공정한 스케줄링 방식이라 할 수 있다.


CPU 버스트 시간을 매우 작은 단위로 나누어 실행하기 때문에 자신이 CPU를 쓰고자 하는 양이 적으면 소요 시간(turn around time)이 짧아지고, 반대로 CPU를 쓰고자 하는 양이 많으면 소요 시간도 거기에 비례해서 길어진다. 대기 시간(waiting time) 역시 자신이 사용하는 CPU 버스트 시간에 비례해 증가하므로 공정하다고 할 수 있다. 


예를 들어, CPU 버스트 시간이 1초인 프로세스가 작업을 완료하는 데에 10초가 걸렸다면, CPU 버스트 시간이 10초인 프로세스는 그것의 10배인 100초가 소요되는 것이다. 한편 SJF 스케줄링의 경우에는 CPU 버스트 시간이 1초인 프로세스의 소요 시간이 10초라고 해도 CPU 버스트 시간이 10초인 프로세스는 이보다 더 짧은 CPU 버스트를 가진 프로세스가 계속 도착할 경우 무한정 기다릴 수 있다.


라운드 로빈 스케줄링에서 할당 시간을 너무 짧게 설정하면 문맥 교환(context switch)의 오버헤드가 증가해 전체 시스템의 성능을 저하시킬 수 있다.


FCFS 스케줄링과 라운드 로빈 스케줄링을 대기 시간과 응답 시간, 소요 시간 관점에서 비교해 보자.
* CPU 버스트 시간이 10인 프로세스 10개가 모두 시각 0에 도착했을 경우 FCFS 스케줄링에서는 P1이 CPU를 다 사용한 후 P2, P3가 차례대로 CPU를 사용하는 식으로 진행된다. 따라서 P1의 대기 시간은 0, P2의 대기 시간은 10, P3의 대기 시간은 20, ... , P10의 대기 시간은 90이 된다. 
    * 응답 시간도 대기 시간과 동일한 값을 가지게 된다. 따라서 10개의 프로세스에 대한 평균 대기 시간과 평균 응답시간은 모두 45가 된다. 
    * 소요 시간을 구해 보면, P1의 소요 시간은 10, P2의 소요 시간은 20, P3의 소요 시간은 30, ... , P10의 소요 시간은 100이 된다. 따라서 평균 소요 시간은 55가 된다.
    * 이 방식의 특징은 프로세스를 하나씩 끝내는 방식으로 시간이 흐름에 따라 적어도 하나씩은 처리가 완료된 프로세스가 발생하여 평균 대기 시간이나 평균 소요 시간 측면에서는 좋은 결과를 얻을 수 있다. 그러나, 프로세스 간에 대기 시간이나 소요 시간의 편차가 매우 크며, 평균 응답 시간이 지나치게 길어지는 문제점이 있다.
* 동일한 예에 대해서 라운드 로빈 스케줄링을 적용한 경우 라운드 로빈 스케줄링에서 할당 시간을 극단적으로 짧게 설정하면, 10개의 프로세스가 100이라는 시간에 거의 동시에 자신의 CPU 버스트를 끝마치게 된다. 따라서, 대기 시간이나 처리 시간의 편차가 크지 않다. 그러나, 중간 산출물이 없이 모든 프로세스가 마지막이 되어서야 함께 끝마쳐지므로 평균 대기 시간과 평균 소요 시간이 각각 90과 100에 이르게 되어 FCFS보다 비효율적이다. 
    * FCFS에서는 CPU를 먼저 쓰고 나가는 프로세스의 소요 시간 및 대기 시간이 짧아지는 반면 라운드 로빈 스케줄링에서는 CPU를 조금씩 같이 쓰고 거의 동시에 끝나게 되어 소요 시간 및 대기 시간이 가장 오래 기다린 프로세스에 맞추어지게 된다. 따라서, 라운드 로빈 스케줄링이 FCFS에 비해 평균 대기 시간 및 평균 소요 시간이 거의 두 배가 된다. 
    * 이는 동일한 CPU 버스트 시간을 가지는 프로세스들에 대해 라운드 로빈 스케줄링을 적용할 경우 평균 대기 시간 및 평균 소요 시간이 더 길어진다는 의미가 된다. 그러나, 이 경우에도 평균 응답 시간은 더 짧아지게 된다.
* 일반적인 시스템에서는 위와 같이 프로세스의 CPU 버스트 시간이 균일하지 않고 각자 다른 CPU 버스트 및 I/O 버스트를 가지는 경우가 대부분이다. 이러한 경우에 라운드 로빈 스케줄링을 적용하면 프로세스의 CPU 사용량에 비례해 소요 시간이 증가하게 되므로 매우 합리적이라 할 수 있다.
* 이에 비해 FCFS는 프로세스마다 소요되는 시간의 편차가 매우 크다. 특히, CPU 버스트가 긴 프로세스가 먼저 도착하는 경우에는 소요 시간의 편차가 클뿐 아니라 그 평균값도 극단적으로 증가하게 된다.


&nbsp;      
### 멀티 레벨 큐
멀티 레벨 큐(multi-level queue)란 준비 큐를 여러 개로 분할해 관리하는 스케줄링 기법이다. 즉, 프로세스들이 CPU를 기다리기 위해 한 줄로 서는 것이 아니라 여러 줄로 서는 것을 말한다.


CPU는 하나밖에 없으므로 이 경우 어떤 줄에 서 있는 프로세스를 우선적으로 스케줄링할 것인가 하는 문제가 발생한다. 또한, 프로세스가 도착했을 때 어느 줄에 세워야 할지 결정하는 메커니즘도 필요하다.


멀티 레벨 큐는 성격이 다른 프로세스들을 별도로 관리하고 프로세스의 성격에 맞는 스케줄링을 적용하기 위해 준비 큐를 별도로 두게 된다.


멀티 레벨 큐에서 준비 큐는 보통 대화형 작업을 담기 위한 전위 큐(foreground queue)와 계산 위주의 작업을 담기 위한 후위 큐(back-ground queue)로 분할하여 운영한다. 
* 전위 큐에서는 응답 시간을 짧게 하기 위해 라운드 로빈 스케줄링을 사용하고 계산 위주의 작업을 위한 후위 큐에서는 응답 시간이 큰 의미를 가지지 않기 때문에 FCFS 스케줄링 기법을 사용해 문맥 교환 오버헤드를 줄이도록 한다.


멀티 레벨 큐에서는 또 다른 스케줄링이 필요한데 이는 여러 개의 준비 큐에 대해서 어느 큐에 먼저 CPU를 할당할 것인지를 결정하는 스케줄링이다.  큐에 대한 스케줄링인 고정 우선순위 방식(fixed priority scheduling)에서는 큐에 고정적인 우선순위를 부여해 우선순위가 높은 큐를 먼저 서비스하고 우선순위가 낮은 큐는 우선순위가 높은 큐가 비어 있을 때에만 서비스하게 된다. 즉, 전위 큐와 후위 큐를 사용하는 방식에서는 전위 큐에 있는 프로세스에게 우선적으로 CPU가 할당되고, 전위 큐가 비어 있을 경우에만 후위 큐에 있는 프로세스에게 CPU가 할당될 수 있다. 


이외에 타임 슬라이스(time slice) 방식은 큐에 대한 기아 현상을 해소할 수 있는 방식으로 각 큐에 CPU 시간을 적절한 비율로 할당하게 된다.


&nbsp;      
### 멀티 레벨 피드백 큐
멀티 레벨 피드백 큐(multilevel feedback queue)는 CPU를 기다리는 프로세스를 여러 큐에 줄 세운다는 측면에서 멀티 레벨 큐와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동 가능하다는 점이 다르다.


노화(aging) 기법을 멀티 레벨 피드백 큐 방식으로 구현할 수 있다. 우선순위가 낮은 큐에서 오래 기다렸으면 우선순위가 높은 큐로 승격시키는 방식이 그것이다.


큐에 대한 스케줄링 방식으로는 최상위 큐가 우선적으로 CPU를 배당하고, 상위 큐가 비었을 때에만 하위 큐에 있는 프로세스들이 CPU를 할당받을 수 있게 된다. 이러한 방식은 라운드 로빈 스케줄링을 한층 더 발전시켜 프로세스의 CPU 작업 시간을 다단계로 분류하여 작업 시간이 짧은 프로세스일수록 더욱 빠른 서비스가 가능하도록 하고, 작업 시간이 긴 프로세스에 대해서는 문맥 교환 없이 CPU 작업에만 열중할 수 있는 FCFS 방식을 채택하도록 한다.


&nbsp;      
### 다중 처리기 스케줄링
CPU가 여러 개인 시스템을 다중 처리기 시스템(multi-processor system)이라고 부른다. 다중 처리기 환경에서의 CPU 스케줄링은 CPU가 하나인 시스템에서보다 더욱 복잡한 문제가 된다. 


프로세스를 준비 큐에 한 줄로 세워서 각 CPU가 알아서 다음 프로세스를 꺼내어 가도록 할 수 있다. 그러나 반드시 특정 CPU에서 수행되어야 하는 프로세스가 있는 경우에는 문제가 복잡해진다. 이런 상황에서는 한 줄이 아니라 각 CPU 별로 줄 세우기를 할 수도 있다.


여러 줄 세우기를 하는 경우 일부 CPU에 작업이 편중되는 현상이 발생할 수 있다. 이와 같은 현상을 방지해 각 CPU 별 부하를 적절히 분산되도록 하는 부하 균형(load balancing) 메커니즘이 필요하다.


다중 처리기의 스케줄링 방식은 대칭형 다중 처리(symmetric multi-processing)와 비대칭형 다중 처리(asymmetric multiprogramming)로 나누어 볼 수 있다.
* 대칭형 다중 처리는 각 CPU가 각자 알아서 스케줄링을 결정하는 방식이고, 비대칭형 다중 처리는 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터의 접근을 책임지고 나머지 CPU는 거기에 따라 움직이는 방식을 말한다.


&nbsp;      
### 실시간 스케줄링
시분할 시스템(time sharing system)에서는 작업의 처리가 빠를수록 좋지만 특정 시간 이내에 처리하지 못했다고 해서 심각한 상황이 발생하는 것은 아니다. 즉, 작업에 데드라인이 존재하지 않는다. 하지만 실시간 시스템(real-time system)에서는 각 작업마다 주어진 데드라인이 있어 정해진 데드라인 안에 반드시 작업을 처리해야 한다.


실시간 시스템은 경성 실시간 시스템(hard real-time system)과 연성 실시간 시스템(soft real-time system)으로 나뉜다.
* 경성 실시간 시스템은 시간을 정확히 지켜야 하는 시스템으로 정해진 시간 안에 반드시 작업이 완료되도록 스케줄링해야 한다. (미사일 발사, 원자로 제어 등)
* 연성 실시간 시스템은 데드라인이 존재하기는 하지만 데드라인을 지키지 못했다고 해서 위험한 상황이 발생하지는 않는다. (멀티미디어 스트리밍 시스템)


실시간 환경에서의 스케줄링(real-time scheduling)은 빠른 서비스도 중요하지만 데드라인을 지키는 서비스가 더욱 중요하다. 실시간 환경에서는 먼저 온 요청을 먼저 처리하기보다는 데드라인이 얼마 남지 않은 요청을 먼저 처리하는 EDF(Earlist Deadline First) 스케줄링을 널리 사용하게 된다.


&nbsp;      
## 스케줄링 알고리즘의 평가

스케줄링 알고리즘의 성능을 평가하는 방법으로는 큐잉 모델(que-ueing model), 시뮬레이션(simulation), 구현 및 실측(implementation & measurement) 방식이 있다.
* 큐잉 모델은 주로 이론가들이 수행하는 방식으로 확률 분포를 통해 프로세스들의 도착률과 CPU의 처리율을 입력값으로 주면 복잡한 수학적 계산을 통해 각종 성능 지표인 CPU의 처리량, 프로세스의 평균 대기 시간 등을 구하게 된다.
* 구현 및 실측은 구현가들이 수행할 수 있는 방식으로 운영 체제 커널의 소스 코드 중에서 CPU 스케줄링을 수행하는 코드를 수정해서 커널을 컴파일한 후 시스템에 설치한다. 그런 다음 동일한 프로그램을 원래 커널과 CPU 스케줄러를 수정한 커널에서 수행시켜 보고 실행 시간을 측정하여 알고리즘의 성능을 평가한다.
* 시뮬레이션은 가상으로 CPU 스케줄링 프로그램을 작성한 후 프로그램의 CPU 요청을 입력값으로 넣어 어떠한 결과가 나오는지를 확인하는 방법이다.
    * 입력값은 가상으로 생성할 수도 있고 실제 시스템에서의 CPU 요청 내역을 추출해 사용할 수도 있다.
    * 실제 시스템에서 추출한 입력값을 트레이스(trace)라 부르고 트레이스는 몇 초에 어떤 프로세스가 도착하고, 각각 CPU 버스트 시간을 얼마로 하는지에 대한 정보를 시간 순서대로 적어 놓은 파일이다.


&nbsp;      
### [by. 0junChoi](https://github.com/0jun0815) email: <0jun0815@gmail.com>
### 출처: [운영 체제와 정보 기술의 원리](http://book.naver.com/bookdb/book_detail.nhn?bid=4392911), [반효경 운영체제 강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323)

