# 가상 메모리 


운영체제는 프로그램이 물리적 메모리를 고려할 필요 없이 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램 하는 것을 지원한다. 이렇게 되면 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데 이러한 메모리 공간을 가상 메모리(virtual memory)라고 부른다. 즉, 가상 메모리는 프로세스마다 각각 0번지부터의 주소 공간을 가지게 되며, 이들 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크의 스왑 영역에 존재하게 된다.


프로세스의 주소 공간을 메모리로 적재하는 단위에 따라 가상 메모리 기법은 요구 페이징(demand paging) 방식과 요구 세그먼테이션(demand segmentation) 방식으로 구현될 수 있다. 대부분의 경우 요구 페이징 방식을 사용한다.


* [요구 페이징](#요구-페이징)
    * [요구 페이징의 페이지 부재 처리](#요구-페이징의-페이지-부재-처리)
    * [요구 페이징의 성능](#요구-페이징의-성능)
* [페이지 교체](#페이지-교체)
    * [최적 페이지 교체(optimal page replacement)](#최적-페이지-교체(optimal-page-replacement))
    * [FIFO 알고리즘](#fifo-알고리즘)
    * [LRU 알고리즘](#lru-알고리즘)
    * [LFU 알고리즘](#lfu-알고리즘)
    * [클럭 알고리즘](#클럭-알고리즘)
* [페이지 프레임의 할당](#페이지-프레임의-할당)
* [전역 교체와 지역 교체](#전역-교체와-지역-교체)
* [스레싱](#스레싱)
    * [워킹셋 알고리즘](#워킹셋-알고리즘)
    * [페이지 부재 빈도 알고리즘](#페이지-부재-빈도-알고리즘)



&nbsp;      
## 요구 페이징
요구 페이징이란 프로그램 실행시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 메모리에 올리는 방식. 요구 페이징 기법에서는 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.


요구 페이징 기법에서는 당장 실행에 필요한 페이지만을 메모리에 적재하기 때문에, 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 올리는 데 들었던 입출력 오버헤드도 줄어든다. 이는 사용되지 않을 주소 영역에 대한 입출력까지 수행하던 기존 방식에 비해 응답 시간을 단축시킬 수 있으며, 시스템이 더 많은 프로세스를 수용할 수 있게 해준다. 주된 효용은 프로그램이 물리적 메모리의 용량 제약을 벗어날 수 있도록 한다는 점이다. 프로그램을 구성하는 페이지 중 일부만을 메모리에 적재하게 되므로, 물리적 메모리의 용량보다 큰 프로그램도 실행할 수 있기 때문이다.


가상 메모리 기법에서는 프로세스가 실행되는 동안 일부 페이지는 메모리에, 나머지 페이지는 디스크 스왑 영역에 존재한다. 이러한 시스템에서는 특정 프로세스를 구성하는 페이지 중에서 어떤 페이지가 메모리에 존재하고 존재하지 않는지를 구별하기 위한 방안이 필요. 요구 페이징에서는 유효-무효 비트(valid-invalid bit)를 두어 각 페이지가 메모리에 존재하는지를 표시하게 된다. 이 비트는 각 프로세스를 구성하는 모든 페이지에 대해 존재해야 하므로 페이지 테이블의 각 항목별로 저장된다.


특정 페이지가 참조되어 메모리에 적재되는 경우 페이지의 유효-무효 비트는 유효값으로, 디스크의 스왑 영역으로 쫓겨날 때에는 다시 무효값을 가지게 된다. 유효-무효 비트의 값이 무효인 경우는 페이지가 현재 메모리에 없는 경우를 의미할 수도 있지만 경우에 따라서는 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않는 경우도 있다. CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우를 '페이지 부재(page fault)'가 일어났다고 말한다.


### 요구 페이징의 페이지 부재 처리
CPU가 무효 페이지에 접근하면, 주소 변환을 담당하는 하드웨어인 MMU(Memory Management Unit)가 페이지 부재 트랩(page fault trap)을 발생시키게 된다. 그러면 CPU 제어권이 커널 모드(kernal mode)로 전환되고, 페이지 부재 처리 루틴(page fault handler)이 호출되어 다음과 같은 순서로 페이지 부재를 처리한다:
1. 해당 페이지에 대한 접근이 적법한지를 체크한다. 사용되지 않는 주소 영역에 속한 페이지를 접근하려 했거나 해당 페이지에 대한 접근 권한 위반(protection violation)일 경우 해당 프로세스를 종료시킨다.
2. 접근이 적법할 경우 물리적 메모리에서 비어 있는 프레임(free frame)을 할당받아 그 공간에 해당 페이지를 읽어온다. 만약 비어 있는 프레임이 없다면 기존에 메모리에 올라와 있는 페이지 중 하나를 디스크의 스왑 영역으로 쫓아낸다(스왑 아웃).
3. 요청된 페이지를 디스크로부터 메모리로 적재하기까지는 오랜 시간이 소요되므로 페이지 부재를 발생시킨 프로세스는 CPU를 빼앗기고 봉쇄 상태가 된다.
4. 디스크 입출력이 완료되어 인터럽트가 발생하면, 페이지 테이블에서 해당 페이지의 유효-무효 비트를 유효로 설정, 봉쇄되었던 프로세스를 준비 큐로 이동시킨다.
5. 이 프로세스가 다시 CPU를 할당받으면 PCB에 저장해 두었던 값을 복원, 이전에 중단되었던 명령(instruction)부터 실행을 재개한다.


### 요구 페이징의 성능
성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도이다. 페이지 부재가 일어나면, 요청된 페이지를 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생하기 때문. 즉, 페이지 부재 발생이 적을수록 요구 페이징의 성능은 향상된다.


요구 페이징의 성능은 다음과 같이 요청항 페이지를 참조하는데 걸리는 유효 접근 시간으로 측정한다:
```
- 유효 접근 시간(effective access time)
    = (1-P) * 메모리 접근 시간
    + P * (페이지 부재 발생 처리 오버헤드
        + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드
        + 요청된 페이지의 스왑 인 오버헤드
        + 프로세스의 재시작 오버헤드)
    
- 페이지 부재 발생 비율(page fault rate) 0<=P<=1
    P=0: 페이지 부재가 한 번도 일어나지 않은 경우, 메모리에 접근하는 시간만이 소요
    P=1: 모든 참조 요청에서 페이지 부재가 발생한 경우
```


&nbsp;
## 페이지 교체
페이지 부재시 물리적 메모리에 빈 프레임이 존재하지 않는 경우 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업을 페이지 교체(page replacement)라고 한다. 페이지 교체를 할 때에 어떠한 프레임에 있는 페이지를 쫓아낼 것인가를 결정하는 알고리즘을 교체 알고리즘(replacement algorithm)이라 하고, 알고리즘의 목표는 페이지 부재율을 최소화하는 것이다. 그러므로 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는 것이 성능을 향상시킬 수 있는 방안이다. 페이지 교체 알괴즘의 성능은 주어진 페이지 참조열(page reference string)에 대해 페이지 부재율을 계산함으로써 평가할 수 있다.


페이지 참조열은 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것이다. 해당 번호의 페이지가 메모리에 이미 올라와 있으면 메모리에 적중(hit)되었다고 하고, 없는 경우에는 페이지 부재가 발생했다고 말한다.


### 최적 페이지 교체(optimal page replacement)
페이지 교체시 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아내는 최적 알고리즘을 빌레디의 최적 알고리즘(Belady's optimal algorithm) 또는 MIN, OPT라고 부른다.


![optimal-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/optimal-algorithm.png)


* 초기에는 메모리가 비어 있기 때문에 처음 4회까지의 페이지 참조시에는 페이지 부재가 불가피하게 발생한다.
* 페이지 5를 참조하려 할 때 페이지 부재가 발생, 메모리에 빈 공간이 없으므로 현재 메모리에 올라와 있는 페이지 중 하나를 선정해 요청된 페이지와 교체하게 되는데, 이 때 빌레디의 최적 알고리즘은 가장 먼 미래에 참조될 페이지를 선정하게 된다. 따라서 페이지 4를 내 쫓고 그 자리에 페이지 5를 적재한다.
* 12회의 페이지 참조가 일어나는 동안 총 6회의 페이지 부재가 발생한다.


이 알고리즘은 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제 하에 알고리즘을 운영하므로 실제 시스템에서 온라인으로 사용할 수 있는 알고리즘은 아니다. 따라서, 오프라인 알고리즘이라고 부른다.


빌레디의 오프라인 최적 알고리즘은 어떠한 알고리즘을 사용하는 경우보다도 가장 적은 페이지 부재율을 보장하므로 다른 알고리즘의 성능에 대한 상한선(upper bound)을 제공한다.


### FIFO 알고리즘
FIFO(First In First Out) 알고리즘은 페이지 교체시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓는다. 페이지 향후 참조 가능성을 고려하지 않고, 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기 때문에 비효율적인 상황이 발생할 수 있다.


![fifo-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/fifo-algorithm.png)


* 페이지 프레임이 3개인 경우 9번의 페이지 부재가 발생했으나, 4개인 경우에는 오히려 페이지 부재가 10번으로 증가했다. 페이지를 적재할 수 있는 물리적 메모리의 공간이 늘어났음에도 오히려 성능은 더 나빠진 것이다.
* FIFO 알고리즘에서 메모리를 증가시켜 주었음에도 불구하고 페이지 부재가 오히려 늘어나는 상황을 FIFO의 이상현상(FIFO anomaly)라고 부른다.


### LRU 알고리즘
LRU(Least Recently Used) 알고리즘은 시간 지역성(temporal locality)를 활용해서 페이지 교체시 가장 오래 전에 참조가 이루어진 페이지를 내쫓는다. 마지막 참조 시점이 가장 오래된 페이지를 교체하게 되는 것이다.
* 시간 지역성: 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질


![lru-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/lru-algorithm.png)


* 총 12번의 페이지 참조가 일어나는 동안 8회의 페이지 부재를 발생시킨다.
* 초기에는 페이지 프레임이 모두 비어 있으므로, 네 번의 페이지 부재가 일어난다.
* 그 후 페이지 1, 2는 메모리 내에 존재하므로 적중이 일어나고, 페이지 5가 참조될 때 페이지 부재가 발생한다. 이 때 페이지 5는 페이지 3과 교체되는데, 이는 페이지 3이 가장 오래 전에 참조된 페이지이기 때문이다.


### LFU 알고리즘
LFU(Least Frequently Used) 알고리즘은 페이지의 참조 횟수로 교체 시킬 페이지를 결정한다. 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수(reference count)가 가장 적었던 페이지를 내쫓고 그 자리에 새로 참조될 페이지를 적재한다. 최저 참조 횟수를 가진 페이지가 여러 개 존재하는 경우에는 임의로 하나를 선정해 그 페이지를 내쫓는다.


페이지의 참조 횟수를 계산하는 방식에 따라 Incache-LFU와 Perfec-LFU의 서로 다른 방식으로 구현할 수 있다. 
* Incache-LFU: 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식. 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 1부터 새롭게 시작된다.
* Perfect-LFU: 메모리에 올라와 있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트한다. 어떤 페이지가 4번 참조된 후 메모리에서 쫓겨났다 다시 들어온 경우 참조 횟수는 기존 참조 횟수인 4번이 누적되어 총 5번이된다. 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 오버헤드가 상대적으로 더 크다.


LFU 알고리즘은 LRU 알고리즘보다 오랜 시간 동안의 참조 기록을 반영할 수 있다는 장점이 있다. LRU는 직전 참조된 시점만을 반영하지만 LFU는 참조 횟수를 통해 장기적인 시간 규모에서의 참조 성향을 고려하기 때문이다. 하지만, LFU는 시간에 따른 페이지 참조의 변화를 반영하지 못하고, LRU보다 구현이 복잡하다는 단점이 있다.


다음은 LRU 알고리즘과 LFU 알고리즘이 페이지 교체를 수행하면서 발생할 수 있는 장점점의 극단적인 예이다:


![lfu-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/lfu-algorithm.png)


* 현재 시간에 5번 페이지가 참조될 때, LRU 알고리즘은 1번 페이지를 교체 대상으로 선정한다. 이는 1번 페이지가 가장 오래전에 참조되었기 때문이다. 한편, 1번 페이지는 마지막 참조 시점이 다른 페이지들에 비해 오래되기는 했지만 참조 횟수가 가장 많았다. LRU 알고리즘은 이러한 사실을 인지하지 못한다.
* LFU 알고리즘은 4번 페이지를 교체 대상을 선정한다. 이는 4번 페이지가 참조 횟수가 가장 적었기 때문이다. 그러나, 4번 페이지는 가장 최근에 참조된 페이지로 지금부터 인기를 얻기 시작하는 페이지일 수 있다. LFU 알고리즘은 이러한 사실을 인지하지 못한다.


### 클럭 알고리즘
LRU와 LFU 알고리즘은 페이지의 최근 시각 및 참조 횟수를 소프트웨어적으로 유지해야 하므로 알고리즘의 운영에 시간적인 오버헤드가 발생한다. 클럭 알고리즘(clock algorithm)은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식이다.


클럭 알고리즘은 LRU를 근사(approximation)시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로도 불린다. 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체하는데, 최근에 참조되지 않은 페이지를 교체 대상으로 선정한다는 측면에서 LRU와 유사하지만, 하드웨어적인 지원으로 동작하기 때문에 LRU에 비해 교체 페이지의 선정이 훨씬 빠르게 결정된다. 따라서 대부분의 시스템에서 페이지 교체 알고리즘으로 클럭 알고리즘을 채택한다.


클럭 알고리즘은 교체할 페이지를 선정하기 위해 페이지 프레임들의 참조 비트(reference bit)를 순차적으로 조사한다:
1. 참조 비트는 각 프레임마다 하나씩 존재하며 그 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅된다. 
2. 참조 비트가 1인 페이지는 0으로 바꾼 후 그냥 지나가고 참조 비트가 0인 페이지는 교체한다. 
3. 모든 페이지 프레임을 다 조사한 경우 첫 번째 프레임부터 조사 작업을 반복한다.


![clock-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/clock-algorithm.png)


* 참조 비트는 그 페이지가 참조될 때 1로 자동 세팅되므로 시계 바늘이 한 바퀴 돌아오는 동안에 다시 참조가 되지 않을 경우 그 페이지는 교체된다. 이는 참조 비트가 1인 페이지는 0으로 바꾼 후 교체하지 않고 그냥 지나가게 되는데 시계 바늘이 한 바퀴를 돌아왔을 때 여전히 참조 비트가 0이라면 그 시간 동안 다시 참조되지 않았다는 뜻이기 때문이다.
* 자주 사용되는 페이지라면 시계 바늘이 한 바퀴 도는 시간 동안 참조 비트가 1로 세팅되어 교체되지 않으므로 이 알고리즘은 최근에 참조가 일어나지 않은 페이지를 교체하는 알고리즘이다.
* 적어도 시계 바늘이 한 바퀴를 도는 시간만큼 페이지를 메모리에 유지시켜 둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 2차 기회 알고리즘(second chance algorithm)이라고도 부른다.


&nbsp;  
## 페이지 프레임의 할당
기본적인 할당 알고리즘(allocaiton algorithm)은 다음 세 가지로 나누어 볼 수 있다:
* 균등 할당(equal allocation) 방식: 모든 프로세스에게 페이지 프레임을 균일하게 할당
* 비례 할당(proporitional allocation) 방식: 프로세스의 크기에 비례해 페이지 프레임을 할당, 프로세스의 크기가 모두 균일하지 않다는 점에 착안한 방식으로 프로세스의 크기를 고려한 균등 할당 방식으로 볼 수 있다.
* 우선순위 할당(priority allocation) 방식: 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당, 프로세스 중에서 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식이다.


할당 알고리즘만으로는 프로세스의 페이지 참조 특성을 제대로 반영하지 못할 우려가 있다. 예를 들어 현재 수행중인 프로세스의 수가 지나치게 많을 경우 프로세스당 할당되는 메모리량이 과도하게 적어질 수 있기 때문이다. CPU에서 명령을 실행할 때에는 일반적으로 여러 페이지를 동시에 참조하게 된다. 따라서, 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 한다. 경우에 따라서는 일부 프로세스에게 메모리를 할당하지 않는 방식으로 나머지 프로세스들에게 최소한의 메모리 요구량을 충족시킬 수 있어야 한다.


nbsp;       
## 전역 교체와 지역 교체
교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 어떻게 정할지에 따라 교체 방법을 전역 교체(global replacement)와 지역 교체(local replacement)로 구분할 수 있다.
* 전역 교체: 모든 페이지 프레임이 교체 대상이 될 수 있는 방법으로 프로세스마다 메모리를 할당하는 것이 아니라 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거하여 할당되는 메모리량이 가변적으로 변하는 방법이다.
    * 페이지 교체시 다른 프로세스에 할당된 프레임을 빼앗아 올 수 있다. 이는 프로세스별 프레임 할당량을 조절하는 또 다른 방법
    * 전체 시스템 차원에서 더 자주 참조되는 페이지가 메모리에 올라가기 때문에 프로세스의 프레임 할당량이 스스로 조절
    * LRU, LFU, 클럭 등의 알고리즘을 물리적 메모리 내에 존재하는 전체 페이지 프레임들을 대상으로 적용할 경우 이러한 전역 교체 방법이 된다.
* 지역 교체: 현재 수행중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법으로 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다.
    * 프로세스별로 페이지 프레임을 할당하고, 교체할 페이지도 그 프로세스에게 할당된 프레임 내에서 선정한다.
    * LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영할 때에는 지역 교체 방법이 된다.
    
    
&nbsp;
## 스레싱    
최소한의 페이지 프레임을 할당받지 못할 경우 성능상의 심각한 문제가 발생할 수 있는데 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 페이지 부재율(page fault rate)이 크게 상승해 CPU 이용률(CPU utilization)이 급격히 떨어질 수 있기 때문이다. 이와 같은 현상을 스레싱(thrashing)이라고 부른다.


스레싱이 발생하는 시나리오:
* 메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도(MPD: Multi-programming degree)라고 부른다.
1. CPU 이용률이 낮은 경우 운영 체제는 MPD를 높이게 된다.
2. MPD가 과도하게 높아지게 되면 각 프로세스에게 할당되는 메모리의 양이 지나치게 감소하게 된다.
3. 각 프로세스들은 그들이 원할하게 수행되기 위해 필요한 최소한의 페이지 프레임도 할당받지 못하는 상태가 되어 페이지 부재가 빈번히 발생하게 된다.
4. 페이지 부재가 발생하면 디스크 I/O 작업을 수반하므로 문맥 교환을 통해 다른 프로세스에게 CPU가 이양된다.
5. 다른 프로세스 역시 할당받은 메모리 양이 지나치게 적으면 페이지 부재가 발생할 수 밖에 없다.
6. 준비 큐에 있는 모든 프로세스에게 CPU가 한 차례씩 할당되었는데도 모든 프로세스가 다 페이지 부재를 발생시키게 되어 시스템은 페이지 부재를 처리하느라 매우 분주해지고 CPU의 이용률은 급격히 떨어지게 된다.
7. 운영 체제는 메모리에 올라와 있는 프로세스의 수가 적어 이러한 현상이 발생했다고 판단, MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가하게 된다.
8. 프로세스당 할당된 프레임의 수가 더욱 감소하고 페이지 부재는 더욱 빈번히 발생하게 된다.
9. 프로세스들은 서로의 페이지를 교체하며 스왑 인과 스압 아웃을 지속적으로 발생시키고 CPU는 대부분의 시간에 일을 하지 않게 되는데 이러한 상황을 스레싱이라고 부르게 되는 것이다.


![thrashing-diagram](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/thrashing-diagram.png)


메모리 내에 존재하는 프로세스의 수를 증가시키면 CPU 이용률은 이에 비례해서 증가하게 된다. 그러나 어느 한계치를 넘어서면 CPU 이용률이 급격히 떨어지는데 이는 스레싱이 발생했기 때문이다. 따라서, 스레싱이 발생하지 않도록 하면서 CPU 이용률을 최대한 높일 수 있도록 MPD를 조절하는 것이 중요하다.


MPD를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에는 워킹셋 알고리즘(working-set algorithm)과 페이지 부재 빈도 알고리즘(page-fault frequency scheme)이 있다.


### 워킹셋 알고리즘
집중적으로 참조되는 페이지들의 집합을 지역성 집합(locality set)이라고 한다. 워킹셋 알고리즘(working-set algorithm)은 이러한 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘을 뜻한다.


프로세스가 일정 시간 동안 원활히 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합을 워킹셋(working-set)이라고 정의, 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 그 프로세스에게 메모리를 할당한다. 그렇지 않을 경우에는 프로세스에게 할당된 페이지 프레임들을 모두 반납시킨 후 그 프로세스의 주소 공간 전체를 디스크로 스왑 아웃시킨다. 이와 같은 방법을 통해 MPD를 조절하고 스레싱을 방지하게 된다.


워킹셋 알고리즘은 메모리에 올라와 있는 프로세스들의 워킹셋 크기의 합이 프레임 수보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장한다. 이는 MPD를 줄이는 효과가 있게 된다. 반면, 프로세스들의 워킹셋을 모두 할당한 후에도 프레임이 남을 경우, 스왑 아웃되었던 프로세스를 다시 메모리에 올려서 워킹셋을 할당함으로써 MPD를 증가시킨다. 이러한 방식으로 워킹셋 알고리즘은 CPU 이용률을 높게 유지하면서 MPD를 적절히 조절해 스레싱을 방지한다.


![workingset-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/workingset-algorithm.png)


* window size가 10인 경우, 시각이 t1일 때 이 프로세스의 워킹셋이 5개의 페이지로 구성되는 반면 시각이 t2일 때에는 워킹셋이 2개의 페이지로 구성된다.
* 워킹셋 알고리즘은 이처럼 프로세스가 메모리를 많이 필요로 할 때에는 많이 할당하고 적게 필요로 할 때에는 적게 할당하는 일종의 동적인 프레임 할당 기능까지 수행한다.


### 페이지 부재 빈도 알고리즘
페이지 부재 빈도 알고리즘(PFF: Page Fault Frequency Scheme)은 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리량을 동적으로 조절한다.


페이지 부재 빈도 알고리즘은 다음과 같은 원리로 MPD를 조절하면서 CPU 이용률을 높이는 동시에 스레싱을 방지한다:
1. 어떤 프로세스의 페이지 부재율이 시스템에서 미리 정해 놓은 상한값(upper bound)을 넘게 되면 이 프로세스에 할당된 프레임의 수가 부족하다는 것을 의미하므로 이 프로세스에게 프레임을 추가로 더 할당한다. 
2. 추가로 할당할 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 메모리에 올라와 있는 프로세스의 수를 조절한다. 
3. 프로세스의 페이지 부재율이 하한값(lower bound) 이하로 떨어지면 이 프로세스에게 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄인다. 
4. 이런 방식으로 메모리 내에 존재하는 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑 아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높인다.


![pff-algorithm](https://github.com/0jun0815/YJStudy/blob/master/운영체제/가상%20메모리/images/pff-algorithm.png)


&nbsp;
&nbsp;      
### [by. 0junChoi](https://github.com/0jun0815) email: <0jun0815@gamil.com>
### 출처: [운영 체제와 정보 기술의 원리](http://book.naver.com/bookdb/book_detail.nhn?bid=4392911), [반효경 운영체제 강의](http://www.kocw.net/home/search/kemView.do?kemId=1046323)

